# -*- coding: utf-8 -*-
"""Cotton Disease Classification with transfer learning InceptionV3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n6IssbAcFwnrvDCj0-WIVf2pB7DMtCX5

Import the required libraries
"""

# import the libraries as shown below
from matplotlib import pyplot
import matplotlib.pyplot as plt
import os
import cv2
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

from keras.preprocessing.image import img_to_array
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix
from keras.preprocessing.image import ImageDataGenerator,load_img

#from tensorflow.keras.applications.efficientnet import EfficientNetB5
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
#from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Model
import numpy as np
from glob import glob

import seaborn as sns

"""Loading the data for Visualize the train and test data analysis"""

labels = ['diseased cotton leaf', 'diseased cotton plant','fresh cotton leaf','fresh cotton plant']
img_size = 224
def get_data(data_dir):
    data = [] 
    for label in labels: 
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format
                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)
    return np.array(data)

#Now we can easily fetch our train and validation data.
train_path = get_data('/content/drive/MyDrive/Cotton Disease Dataset/train')
test_path = get_data('/content/drive/MyDrive/Cotton Disease Dataset/test')

"""Visualize the train data analysis"""

l = []
for i in train_path:
    if(i[1] == 0):
        l.append("jute")
    if(i[1] == 1):
        l.append("maize")
    if(i[1] == 2):
        l.append("rice")
    if(i[1] == 3):
        l.append("sugarcane")
    if(i[1] == 4):
        l.append("wheat")
sns.set_style('darkgrid')
sns.countplot(l).set_title('Train data')

"""Visualize the test data analysis"""

l = []
for i in test_path:
    if(i[1] == 0):
        l.append("jute")
    if(i[1] == 1):
        l.append("maize")
    if(i[1] == 2):
        l.append("rice")
    if(i[1] == 3):
        l.append("sugarcane")
    if(i[1] == 4):
        l.append("wheat")
sns.set_style('darkgrid')
sns.countplot(l).set_title('Test data')

# re-size all the images to this
IMAGE_SIZE = [224, 224]

#Now we can easily fetch our train and validation data.
train_path = '/content/drive/MyDrive/Cotton Disease Dataset/train'
test_path = '/content/drive/MyDrive/Cotton Disease Dataset/test'

batch_size=32

# Use the Image Data Generator to import the images from the dataset
train_datagen = ImageDataGenerator(rescale=1.0/255.0,
                                   horizontal_flip=True,
                                   vertical_flip=True,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   rotation_range=90)

test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Make sure you provide the same target size as initialied for the image size
train_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=True)

test_generator = test_datagen.flow_from_directory(
        test_path,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False)

# useful for getting number of output classes
folders = glob('/content/drive/MyDrive/Cotton Disease Dataset/train/*')

folders

len(folders)

# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG
# Here we will be using imagenet weights

pre_model = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)


# don't train existing weights
for layer in pre_model.layers:
    layer.trainable = False
    
for (i,layer) in enumerate(pre_model.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

def addTopModel(bottom_model, num_classes, D=512):
    top_model = bottom_model.output
    top_model = Flatten(name = "flatten")(top_model)
    top_model = Dense(D, activation = "relu")(top_model)
    top_model = Dropout(0.4)(top_model)
    top_model = Dense(num_classes, activation = "softmax")(top_model)
    return top_model

num_classes = len(folders)
FC_Layer = addTopModel(pre_model, num_classes)
model = Model(inputs=pre_model.input, outputs=FC_Layer)
print(model.summary())

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# tell the model what cost and optimization method to use
model.compile(loss = 'categorical_crossentropy',
              optimizer = Adam(lr = 0.0001),
              metrics = ['accuracy'])

# fit the model
# Run the cell. It will take some time to execute
train_samples_count=1951
test_samples_count=106
epochs = 40
batch_size = 32

checkpoint = ModelCheckpoint("./weights.h5",
                             monitor="val_loss",
                             mode="min",
                             save_best_only = True,
                             verbose=1)
#Modelcheckpoint
#checkpoint = from tensorflow.keras.callbacks.ModelCheckpoint('./model.h5',monitor='val_loss',mode='min', verbose=1, save_best_only=True)

#callback = [tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss')]


callback = [checkpoint]

history = model.fit_generator(
    train_generator,
    validation_data=test_generator,
    steps_per_epoch = train_samples_count // batch_size,
    validation_steps=test_samples_count // batch_size,
    epochs = epochs,
    callbacks = callback)



# plot the loss
import matplotlib.pyplot as plt
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.xlabel('epochs') 
plt.ylabel('loss')
plt.title('Loss Graph')  
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.xlabel('epochs') 
plt.ylabel('accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

model.load_weights("weights.h5")

true_classes = test_generator.classes
class_indices = train_generator.class_indices
class_indices = dict((v,k) for k,v in class_indices.items())

class_indices

y_pred = model.predict(test_generator)

y_pred = np.argmax(y_pred, axis=1)

print('Confusion Matrix')
print(confusion_matrix(test_generator.classes, y_pred))
print('Classification Report')
target_names = list(class_indices.values())
print(classification_report(test_generator.classes, y_pred, target_names=target_names))

from sklearn.metrics import accuracy_score

vgg_acc = accuracy_score(true_classes, y_pred)
print("Inception V3 Model Accuracy without Fine-Tuning: {:.2f}%".format(vgg_acc * 100))

import seaborn as sns
from sklearn.metrics import confusion_matrix

# Get the names of the 4 classes
class_names = test_generator.class_indices.keys()

def plot_heatmap(y_true, y_pred, class_names, ax, title):
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(
        cm, 
        annot=True, 
        square=True, 
        xticklabels=class_names, 
        yticklabels=class_names,
        fmt='d', 
        cmap=plt.cm.Blues,
        cbar=False,
        ax=ax
    )
    ax.set_title(title, fontsize=16)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha="center")
    ax.set_ylabel('True Label', fontsize=12)
    ax.set_xlabel('Predicted Label', fontsize=12)

fig, (ax1) = plt.subplots(1,1,figsize=(20, 10))

plot_heatmap(true_classes, y_pred,class_names,ax1, title="Transfer Learning InceptionV3")    
    
plt.show()

pwd